{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TirendazAcademy/Tracking-Agents-with-Comet/blob/main/tracking_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U openai langchain tiktoken comet_llm google-search-results cohere chromadb tensorflow-probability kaleido python-multipart"
      ],
      "metadata": {
        "id": "v9mrWMTDCfHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrZXc4DHBxIl"
      },
      "source": [
        "# Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lof54YguBxIn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import comet_llm\n",
        "\n",
        "os.environ[\"COMET_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "\n",
        "comet_llm.init(project=\"comet-langchain-test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzfUNNdeBxIn"
      },
      "source": [
        "# Scraping the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RVcQY6zNBxIo"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the Wikipedia page to scrape\n",
        "url = 'https://en.wikipedia.org/wiki/MrBeast'\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all the text on the page\n",
        "text = soup.get_text()\n",
        "\n",
        "# Open a new file called 'output.txt' in write mode and store the file object in a variable\n",
        "with open('output.txt', 'w', encoding='utf-8') as file:\n",
        "    # Write the string to the file\n",
        "    file.write(text)\n",
        "\n",
        "# load the document\n",
        "with open('./output.txt', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQpjLU5gBxIq"
      },
      "source": [
        "# Data ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bjz8y1zBBxIq"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# define the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([text])\n",
        "\n",
        "# define the embeddings model\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# use the text chunks and the embeddings model to fill our vector store\n",
        "db = Chroma.from_documents(texts, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agFoS85UBxIr"
      },
      "source": [
        "# Tracking an agent with Comet ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLPFL6WTBxIr",
        "outputId": "398e6137-ba6d-4503-ff6b-d31c94e315e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to calculate the age of Mr Beast \n",
            "Action: Calculator \n",
            "Action Input: 25^0.54 \u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 5.687057308780144\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 5.687057308780144\u001b[0m\n",
            "Chain logged to https://www.comet.com/tirendaz/comet-langchain-test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:comet_llm.summary:Chain logged to https://www.comet.com/tirendaz/comet-langchain-test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks.tracers.comet import CometTracer\n",
        "from langchain.agents import initialize_agent, load_tools\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "# Create a comet callback\n",
        "comet_callback = CometTracer()\n",
        "callbacks = [comet_callback]\n",
        "\n",
        "# Define an openai llm\n",
        "llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)\n",
        "\n",
        "# Define a question\n",
        "users_question = \"What is MrBeast's age to the power of 0.54?\"\n",
        "\n",
        "# use our vector store to find similar text chunks\n",
        "results = db.similarity_search(\n",
        "    query=users_question,\n",
        "    n_results=5\n",
        ")\n",
        "\n",
        "# define the prompt template\n",
        "template = \"\"\"\n",
        "\n",
        "You are a chatbot who loves helping people! Given the context sections below, \\\n",
        "answer the question using only the context provided.\n",
        "\n",
        "Context sections:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{users_question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create a prompt template\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
        "\n",
        "# Fill the prompt template\n",
        "prompt_text = prompt.format(context = results, users_question = users_question)\n",
        "\n",
        "# Load tools\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, callbacks=callbacks, verbose=True)\n",
        "\n",
        "# Initialize an agent\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    callbacks=callbacks,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Run the agent\n",
        "agent.run(prompt_text, callbacks=callbacks,)\n",
        "comet_callback.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlLigouIBxIr"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- [All You Need to Know to Build Your First LLM App](https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)\n",
        "- [Conversation QA Gradio ](https://github.com/hwchase17/conversation-qa-gradio/tree/master)\n",
        "\n",
        "Thanks for reading. Let's connect [YouTube](http://youtube.com/tirendazacademy) | [Medium](http://tirendazacademy.medium.com) | [Twitter](http://twitter.com/tirendazacademy) | [Linkedin](https://www.linkedin.com/in/tirendaz-academy) ðŸ˜Ž"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}